# Customer Churn Prediction â€“ End-to-End ML Pipeline

An industry-style machine learning project that predicts whether a telecom customer is likely to churn.
The system is built using modular pipeline architecture, experiment tracking, and reproducible training.

ğŸ“Œ Problem Statement

Customer churn is a major business problem for subscription companies.
The goal of this project is to build a robust ML system that can predict:

Will a customer leave the service? (Yes / No)
This enables proactive retention strategies and revenue protection.

ğŸ§  Solution Overview

This project implements a complete ML lifecycle:

- Data ingestion from MySQL
- Data validation & preprocessing
- Feature transformation
- Model training & hyperparameter tuning
- Experiment tracking with MLflow
- Best model selection
- Artifact persistence for deployment

ğŸ—ï¸ Project Architecture
MySQL â†’ Data Ingestion â†’ Data Transformation â†’ Model Training
                                        â†“
                                   Preprocessor.pkl
                                        â†“
                                   model.pkl
                                        â†“
                                   MLflow / DagsHub

âš™ï¸ Tech Stack

- Python
- Pandas / NumPy
- Scikit-learn
- XGBoost
- MLflow
- DagsHub
- MySQL

ğŸ“‚ Project Structure
ML_PROJECT_2/
â”‚
â”œâ”€â”€ artifacts/                # saved outputs
â”‚   â”œâ”€â”€ model.pkl
â”‚   â””â”€â”€ preprocessor.pkl
â”‚
â”œâ”€â”€ notebook/                 # EDA & experiments
â”‚
â”œâ”€â”€ src/MLProject2/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ data_ingestion.py
â”‚   â”‚   â”œâ”€â”€ data_transformation.py
â”‚   â”‚   â””â”€â”€ model_trainer.py
â”‚   â”‚
â”‚   â”œâ”€â”€ utils.py
â”‚   â”œâ”€â”€ logger.py
â”‚   â””â”€â”€ exception.py
â”‚
â”œâ”€â”€ app.py                    # pipeline runner
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

ğŸ¤– Models Compared

- Logistic Regression
- Random Forest
- Gradient Boosting
- XGBoost
Hyperparameters tuned using GridSearchCV.

ğŸ† Final Result

Best Model: Gradient Boosting
Accuracy: ~80%

(Varies slightly per run due to randomness.)

ğŸ“Š Experiment Tracking

All runs, parameters, and metrics are logged using MLflow and stored on DagsHub.
You can:

âœ” compare models
âœ” inspect metrics
âœ” download artifacts
âœ” reproduce experiments

â–¶ï¸ How to Run:

1ï¸âƒ£ Clone repository
git clone <repo-url>
cd ML_PROJECT_2

2ï¸âƒ£ Create environment
pip install -r requirements.txt

3ï¸âƒ£ Set environment variables (.env)
host=localhost
user=root
password=your_password
db=customer_churn_db

4ï¸âƒ£ Run pipeline
python app.py

ğŸ’¾ Output

After run:

- trained model saved â†’ artifacts/model.pkl
- preprocessor saved â†’ artifacts/preprocessor.pkl
MLflow experiment logged

ğŸ¯ Key Highlights (Resume Points)

- Designed modular, reusable ML pipeline
- Implemented MySQL â†’ ML training workflow
- Applied feature engineering & preprocessing
- Automated hyperparameter tuning
- Integrated MLflow for experiment tracking
- Enabled reproducibility & deployment readiness

ğŸ”® Future Improvements

- Add model explainability (SHAP)
- Build prediction API
- CI/CD integration
- automated retraining
- monitoring


ğŸ‘¤ Author:

Pulkit Chhabra
Aspiring Data Scientist | Machine Learning Enthusiast